{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 선형 회귀 모델\n",
    "\n",
    ": 종속변수와 독립변수 간의 상관관계를 모델링하는 방법\n",
    "\n",
    "    (선형 방정식으로 표현해 예측할 데이터를 분류하는 모델 -> 선형으로 분리할 수 있음 (차원과 관계없음))\n",
    "    \n",
    "    - 2차원 : 단항 회귀 모델 vs 3차원 ~ : 다항 회귀 모델\n",
    "\n",
    "\n",
    "### 1.1 로지스틱 회귀 모델\n",
    "\n",
    ": 선형 모델의 결괏값에 로지스틱 함수를 적용해 0 ~ 1 사이의 값을 갖게 해서 확률로 표현한다. -> 2개로 분류\n",
    "\n",
    "    (1에  가까우면 정답이 1이라고 예측하고, 0에 가까운 경우 0으로 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4 Logistic Regression Example with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Feature Example\n",
    "\n",
    "- TF-IDF 활용해서 문장 벡터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/' \n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv( DATA_IN_PATH + TRAIN_CLEAN_DATA )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5000) \n",
    "# min_df: 설정한 값보다 특정 토큰의 df 값(자유도)이 더 적게 나오면 벡터화 과정에서 제거한다는 의미\n",
    "# anlyzer: 분석하기 위한 기준 단위 (char: 문자단위 / word: 단어단위)\n",
    "# sublinear_tf: 문서의 단어 빈도에 대한 스무딩 여부를 설정하는 값\n",
    "# ngram_range: 빈도의 기본단위를 어느 범위의 n-gram으로 설정할 것인지를 보는 인자\n",
    "# max_features: 각 벡터의 최대 길이, 특징의 길이를 설정하는 것\n",
    "\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "y = np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3881)\t0.04506147239359123\n",
      "  (0, 4129)\t0.04607784447281331\n",
      "  (0, 4337)\t0.04001308835469651\n",
      "  (0, 1493)\t0.03314495265227629\n",
      "  (0, 0)\t0.054660407781216024\n",
      "  (0, 1619)\t0.040403370498837535\n",
      "  (0, 3083)\t0.046079687549730936\n",
      "  (0, 1951)\t0.04618604633963843\n",
      "  (0, 2804)\t0.04640415994477519\n",
      "  (0, 2627)\t0.04304829623020376\n",
      "  (0, 1153)\t0.051684947322936506\n",
      "  (0, 2225)\t0.04703917716139301\n",
      "  (0, 294)\t0.046598741768661085\n",
      "  (0, 3572)\t0.043470981570003044\n",
      "  (0, 958)\t0.04078225166901166\n",
      "  (0, 2396)\t0.04529752186392342\n",
      "  (0, 772)\t0.04208928002687366\n",
      "  (0, 4640)\t0.036067513138924284\n",
      "  (0, 1776)\t0.038328017500383296\n",
      "  (0, 4834)\t0.03836482875414165\n",
      "  (0, 4949)\t0.015777811576590577\n",
      "  (0, 2277)\t0.03402898804011063\n",
      "  (0, 614)\t0.034619389056850976\n",
      "  (0, 3402)\t0.037875470600814684\n",
      "  (0, 4562)\t0.03001653177274675\n",
      "  :\t:\n",
      "  (24999, 2043)\t0.04848474157651679\n",
      "  (24999, 2347)\t0.06978183450498811\n",
      "  (24999, 1320)\t0.05159234341989928\n",
      "  (24999, 3617)\t0.05505645496853158\n",
      "  (24999, 4544)\t0.0403923682938471\n",
      "  (24999, 2941)\t0.045828283778717005\n",
      "  (24999, 1196)\t0.04596769043344006\n",
      "  (24999, 1030)\t0.07389285704457266\n",
      "  (24999, 2877)\t0.04742442558415797\n",
      "  (24999, 4644)\t0.05003706895560835\n",
      "  (24999, 3912)\t0.05176998007467299\n",
      "  (24999, 4168)\t0.06381195131003303\n",
      "  (24999, 620)\t0.07595635048381176\n",
      "  (24999, 2675)\t0.06194377387358398\n",
      "  (24999, 929)\t0.066001818261012\n",
      "  (24999, 3245)\t0.06534705623972441\n",
      "  (24999, 4632)\t0.06573221091277107\n",
      "  (24999, 4740)\t0.16509183778311207\n",
      "  (24999, 3222)\t0.16038532286163235\n",
      "  (24999, 3777)\t0.11739033668466561\n",
      "  (24999, 2910)\t0.06468260298155715\n",
      "  (24999, 1899)\t0.06518792603243315\n",
      "  (24999, 1495)\t0.06843714706811961\n",
      "  (24999, 3545)\t0.06987056523020048\n",
      "  (24999, 1504)\t0.14684545658909468 [1 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습과 검증 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)\n",
    "# train 데이터 중에 validation 데이터를 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 선언 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nsa18\\anaconda3\\envs\\ml_nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgs = LogisticRegression(class_weight='balanced')  \n",
    "# The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 검증 데이터으로 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lgs.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859600\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %f\" % lgs.score(X_eval, y_eval)) # 튜닝 전, 하나의 기준 지표가 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 제출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "\n",
    "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터에 대해 사용했던 객체를 사용해 TF-IDF 값으로 벡터화한다.\n",
    "testDataVecs = vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "test_predicted = lgs.predict(testDataVecs)\n",
    "print(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('naturally film main themes mortality nostalgia loss innocence perhaps surprising rated highly older viewers younger ones however craftsmanship completeness film anyone enjoy pace steady constant characters full engaging relationships interactions natural showing need floods tears show emotion screams show fear shouting show dispute violence show anger naturally joyce short story lends film ready made structure perfect polished diamond small changes huston makes inclusion poem fit neatly truly masterpiece tact subtlety overwhelming beauty',\n",
       " 'movie disaster within disaster film full great action scenes meaningful throw away sense reality let see word wise lava burns steam burns stand next lava diverting minor lava flow difficult let alone significant one scares think might actually believe saw movie even worse significant amount talent went making film mean acting actually good effects average hard believe somebody read scripts allowed talent wasted guess suggestion would movie start tv look away like train wreck awful know coming watch look away spend time meaningful content',\n",
       " 'movie kids saw tonight child loved one point kid excitement great sitting impossible however great fan milne books subtle hide wry intelligence behind childlike quality leading characters film subtle seems shame disney cannot see benefit making movies stories contained pages although perhaps permission use found wishing theater replaying winnie pooh tigger instead characters voices good really bothered kanga music however twice loud parts dialog incongruous film story bit preachy militant tone overall disappointed would go see excitement child face liked lumpy laugh')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.review[0], test_data.review[1], test_data.review[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "answer_dataset = pd.DataFrame({'id': test_data['id'], 'sentiment': test_predicted})\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_tfidf_answer.csv', index=False, quoting=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
