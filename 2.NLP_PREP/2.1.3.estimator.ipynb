{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator\n",
    "\n",
    ": 학습,평가, 예측,배포 기능을 간단하게 사용할 수 있다.\n",
    "\n",
    "ex) session, placeholder&feed_dict 을 더 편하게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['너 오늘 이뻐 보인다', \n",
    "           '나는 오늘 기분이 더러워', \n",
    "           '끝내주는데, 좋은 일이 있나봐', \n",
    "           '나 좋은 일이 생겼어', \n",
    "           '아 오늘 진짜 짜증나', \n",
    "           '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "labels = [[1], [0], [1], [1], [0], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data 사용하기: 입력 함수 구현 가능\n",
    "EPOCH = 100\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "    dataset = dataset.repeat(EPOCH)\n",
    "    dataset = dataset.batch(1)\n",
    "    dataset = dataset.shuffle(len(sequences))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_index) +1\n",
    "EMB_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 함수\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # mode: 현재 모델 함수가 실행되는 모드(학습, 검증, 예측)\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN   # call-back 함수: 파라미터에 함수를 넣어서 콜백\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    embed_input = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE)(features)  # feature: tf.Tensor 혹은 딕셔너리 자료형\n",
    "    embed_input = tf.reduce_mean(embed_input, axis=-1)\n",
    "    \n",
    "    hidden_layer = tf.keras.layers.Dense(128, activation=tf.nn.relu)(embed_input) # 활성함수 relu\n",
    "    output_layer = tf.keras.layers.Dense(1)(hidden_layer)\n",
    "    output = tf.nn.sigmoid(output_layer) # 활성함수 sigmoid\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(output, labels)   # 손실함수(MSE)\n",
    "\n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)  # 옵티마이져\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(     # estimator 객체 생성\n",
    "                  mode=mode,\n",
    "                  train_op=train_op,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './data_out/checkpoint/dnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001829DC24F60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn = model_fn, model_dir = DATA_OUT_PATH + 'checkpoint/dnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\nsa18\\anaconda3\\envs\\ml_nlp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\users\\nsa18\\anaconda3\\envs\\ml_nlp\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\users\\nsa18\\anaconda3\\envs\\ml_nlp\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./data_out/checkpoint/dnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.2500282, step = 1\n",
      "INFO:tensorflow:global_step/sec: 417.781\n",
      "INFO:tensorflow:loss = 0.1339053, step = 101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 1193.66\n",
      "INFO:tensorflow:loss = 0.069996744, step = 201 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1253.35\n",
      "INFO:tensorflow:loss = 0.0018914262, step = 301 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1139.4\n",
      "INFO:tensorflow:loss = 0.0008862113, step = 401 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1089.85\n",
      "INFO:tensorflow:loss = 0.00079952355, step = 501 (0.092 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into ./data_out/checkpoint/dnn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0005363405.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1829dc24a58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(train_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
